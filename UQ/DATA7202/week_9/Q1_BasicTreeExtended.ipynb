{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "diverse-wilderness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BasicTreeExtended.py\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_friedman1, make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from enum import Enum\n",
    "from sklearn.metrics import zero_one_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "czech-voice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deferent loss types\n",
    "class LossType(Enum):\n",
    "    SQER = 1\n",
    "    MISSCLF = 2\n",
    "    GINI = 3\n",
    "    CE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "generous-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makedata():\n",
    "    n_points = 500  # points\n",
    "\n",
    "    X, y = make_friedman1(n_samples=n_points, n_features=5,\n",
    "                          noise=1.0, random_state=100)\n",
    "\n",
    "    return train_test_split(X, y, test_size=0.5, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ignored-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makedata_clf():\n",
    "    n_points = 500  # points\n",
    "\n",
    "    X, y = make_blobs(n_samples=n_points, centers=2, n_features=5,\n",
    "                      random_state=10, cluster_std=5)\n",
    "\n",
    "    return train_test_split(X, y, test_size=0.5, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "obvious-reporter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree node\n",
    "class TNode:\n",
    "    def __init__(self, depth, X, y, lossType):\n",
    "        global n\n",
    "        self.depth = depth\n",
    "        self.X = X  # matrix of explanatory variables\n",
    "        self.y = y  # vector of response variables\n",
    "        self.lossType = lossType\n",
    "        # initialize optimal split parameters\n",
    "        self.j = None\n",
    "        self.xi = None\n",
    "        # initialize children to be None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        # initialize the regional predictor\n",
    "        self.g = None\n",
    "\n",
    "    def CalculateLoss(self):\n",
    "        if (len(self.y) == 0):\n",
    "            return 0\n",
    "\n",
    "        if (self.lossType == LossType.SQER):\n",
    "            return np.sum(np.power(self.y - self.y.mean(), 2))\n",
    "\n",
    "        # count class instances\n",
    "        c0 = len(self.y[self.y == 0])\n",
    "        c1 = len(self.y[self.y == 1])\n",
    "\n",
    "        if (self.lossType == LossType.MISSCLF):\n",
    "            return (1 - max(c0, c1) / (c0 + c1)) * (len(self.y) / n)\n",
    "\n",
    "        p0 = c0 / (c0 + c1)\n",
    "        p1 = c1 / (c0 + c1)\n",
    "\n",
    "        if (self.lossType == LossType.GINI):\n",
    "            return (p0 * (1 - p0) + p1 * (1 - p1)) * (len(self.y) / n)\n",
    "\n",
    "        if (self.lossType == LossType.CE):\n",
    "            if (p0 == 0 or p1 == 0):\n",
    "                return 0\n",
    "            else:\n",
    "                return (-0.5 * (p0 * np.log2(p0) + p1 * np.log2(p1))) * (len(self.y) / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "victorian-breath",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Construct_Subtree(node, max_depth, lossType):\n",
    "    if (node.depth == max_depth or len(node.y) == 1):\n",
    "        node.g = node.y.mean()\n",
    "\n",
    "    else:\n",
    "        j, xi = CalculateOptimalSplit(node, lossType)\n",
    "        node.j = j\n",
    "        node.xi = xi\n",
    "\n",
    "        Xt, yt, Xf, yf = DataSplit(node.X, node.y, j, xi)\n",
    "\n",
    "        if (len(yt) > 0):\n",
    "            node.left = TNode(node.depth + 1, Xt, yt, lossType)\n",
    "            Construct_Subtree(node.left, max_depth, lossType)\n",
    "\n",
    "        if (len(yf) > 0):\n",
    "            node.right = TNode(node.depth + 1, Xf, yf, lossType)\n",
    "            Construct_Subtree(node.right, max_depth, lossType)\n",
    "\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "drawn-development",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data-set\n",
    "def DataSplit(X, y, j, xi):\n",
    "    ids = X[:, j] <= xi\n",
    "    Xt = X[ids == True, :]\n",
    "    Xf = X[ids == False, :]\n",
    "    yt = y[ids == True]\n",
    "    yf = y[ids == False]\n",
    "    return Xt, yt, Xf, yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "known-radical",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateOptimalSplit(node, lossType):\n",
    "    X = node.X\n",
    "    y = node.y\n",
    "    best_var = 0\n",
    "    best_xi = X[0, best_var]\n",
    "    best_split_val = node.CalculateLoss()\n",
    "\n",
    "    m, n = X.shape\n",
    "\n",
    "    for j in range(0, n):\n",
    "        for i in range(0, m):\n",
    "            xi = X[i, j]\n",
    "            Xt, yt, Xf, yf = DataSplit(X, y, j, xi)\n",
    "            tmpt = TNode(0, Xt, yt, lossType)\n",
    "            tmpf = TNode(0, Xf, yf, lossType)\n",
    "            loss_t = tmpt.CalculateLoss()\n",
    "            loss_f = tmpf.CalculateLoss()\n",
    "            curr_val = loss_t + loss_f\n",
    "            if (curr_val < best_split_val):\n",
    "                best_split_val = curr_val\n",
    "                best_var = j\n",
    "                best_xi = xi\n",
    "    return best_var, best_xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "legitimate-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(X, node):\n",
    "    if (node.right == None and node.left != None):\n",
    "        return Predict(X, node.left)\n",
    "\n",
    "    if (node.right != None and node.left == None):\n",
    "        return Predict(X, node.right)\n",
    "\n",
    "    if (node.right == None and node.left == None):\n",
    "        return node.g\n",
    "    else:\n",
    "        if (X[node.j] <= node.xi):\n",
    "            return Predict(X, node.left)\n",
    "        else:\n",
    "            return Predict(X, node.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "comic-astrology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic tree: tree loss =  0.08799999999999997\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    X_train, X_test, y_train, y_test = makedata_clf()\n",
    "    maxdepth = 10  # maximum tree depth\n",
    "\n",
    "    n = len(X_train)\n",
    "\n",
    "    # define loss type\n",
    "    # lossType = LossType.GINI\n",
    "    # lossType = LossType.CE\n",
    "    lossType = LossType.MISSCLF\n",
    "\n",
    "    # Create tree root at depth 0\n",
    "    treeRoot = TNode(0, X_train, y_train, lossType)\n",
    "\n",
    "    # Build the regression tree with maximal depth equal to max_depth\n",
    "    Construct_Subtree(treeRoot, maxdepth, lossType)\n",
    "\n",
    "    # Predict\n",
    "    y_hat = np.zeros(len(X_test))\n",
    "    for i in range(len(X_test)):\n",
    "        y_hat[i] = Predict(X_test[i], treeRoot)\n",
    "\n",
    "    print(\"Basic tree: tree loss = \", zero_one_loss(y_test, np.int64(y_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-scroll",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-verification",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
