1 # Coefficients:
#            Estimate
#(Intercept) 33.89280
# fheight    0.51401

#B0(y - Intercept) = 33.892980
#B1(Slope) = 0.51401

#y = B0 + B1*x
#sonhight = 33.89280 + 051401 * fatherhighthttps://data7001-1649dce6.uqcloud.net/notebooks/text/Untitled.ipynb

#Sonheight varies is a function of the father's height, as shown in the above equation.

2 R-squared= Explained variation / Total variation
It means that 25.12% of variation in the height of son can be completely explained by the height of father

3 predicted_sonheight = B0 + B1 * fatherheight; 
fit_predicted_sonheitht = 33.89280 + 0.51401 * 67 = 68.33147 

4: newfheight<-seq(min(fheight$fheight)-1, max(fheight$fheight)+1, by=0.1)
lmfitci<-predict(lmfit, data.frame(fheight=newfheight), interval='prediction',level=0.95,type='response')
plot(fs_height$fheight,fs_height$sheight,main='Father and Son Heights', xlab='Father Heights (in)',ylab='Son Heights (in)',col=rgb(1,0.3,0.1,0.5))
lines(newfheight,lmfitci[,1],col='black',lty=1)
lines(newfheight,lmfitci[,2],col='black',lty=2)
lines(newfheight,lmfitci[,3],col='black',lty=2)

5: limits = predict(lmfit, data.frame(fheight=fs_height$fheight),interval='predict',level=0.95,type='response')
count_table = fs_height$sheight>=limits[,2]&fs_height$sheight<=limits[,3]
pos = length(count_table[count_table==TRUE])
sprintf('%i : %i',pos, length(count_table))

6 lmfit_new <- with(tr,lm(sheight~fheight))
summary(lmfit_new)
lmfit_new.res <- resid(lmfit_new)
plot(tr$fheight,lmfit_new.res,
     main="Residual Son Heights from Simple Linear Regression 2", 
     xlab="Father Heights 2 (in)",
     ylab="Residual Son Heights 2 (in)",
     col=rgb(1,0.3,0.1,0.5))
summary(lmfit_new.res)

training_results = predict(lmfit_new, data.frame(fheight=tr$fheight))
resid_results = training_results - tr[,2]
training_square = resid_results * resid_results
mse_training = sum(training_square)/length(training_square)

7 It indicates that the majority of staff who has left the company usually works more than 200 hours a month.


8 (1):error rate = (FP + FN) / (FP + FN + TP + TN) = training=0.2027 or testing=0.2040 
(2):sensitivity = TP / (TP + FN) = training=0.8969 or testing=0.9131
(3):specificity = TN / (TN + FP) = training=0.6645 or testing=0.6271
(4):precision = TP / (TP + FP) = training=0.7808 or testing=0.7794

9 trainidx1<-sample(nrow(HR_best_train), floor(nrow(HR_best_train) * 0.5))
train1<-HR_best_train[trainidx1,]
train2<-HR_best_train[-trainidx1,]


train1$probs<-predict(logfit,data.frame(average_montly_hours=train1$average_montly_hours),type="response")
train1$predleft<-as.integer(train1$probs>=0.5)
table(train1$predleft,train1$left)

train2$probs<-predict(logfit,data.frame(average_montly_hours=train2$average_montly_hours),type="response")
train2$predleft<-as.integer(train2$probs>=0.5)
table(train2$predleft,train2$left)

#error_train1 = (FP + FN) / (FP + FN + TP + TN) = 0.1931
#rror_train2 = (FP + FN) / (FP + FN + TP + TN) = 0.2123

10 library("ROCR")
testROC<-performance(prediction(HR_best_test$probs,HR_best_test$left),"tpr","fpr")
plot(testROC)
abline(a=0, b= 1,lty=2)
testAUC1<-as.double(performance(prediction(HR_best_test$probs,HR_best_test$left),"auc")@y.values)
testAUC1
#The AUC = 0.831329421749594

11 HR_best_test$probs2<-predict(logfit2,data.frame(average_montly_hours=HR_best_test$average_montly_hours,satisfaction_level=HR_best_test$satisfaction_level,number_project=HR_best_test$number_project),type="response")
testROC2<-performance(prediction(HR_best_test$probs2,HR_best_test$left),"tpr","fpr")
plot(testROC2)
abline(a=0, b= 1,lty=2)
testAUC2<-as.double(performance(prediction(HR_best_test$probs2,HR_best_test$left),"auc")@y.values)
testAUC2
#The AUC is 0.918856598084771
#The precision at the beginning part of the chart is very low and then is becoming higher and steady.


12 HR_best_train$probs<-predict(logfit2,data.frame(average_montly_hours=HR_best_train$average_montly_hours,satisfaction_level=HR_best_train$satisfaction_level,number_project=HR_best_train$number_project),type="response")
HR_best_train$predleft<-as.integer(HR_best_train$probs>=0.5)
table(HR_best_train$predleft,HR_best_train$left)

HR_best_test$probs<-predict(logfit2,data.frame(average_montly_hours=HR_best_test$average_montly_hours,satisfaction_level=HR_best_test$satisfaction_level,number_project=HR_best_test$number_project),type="response")
HR_best_test$predleft<-as.integer(HR_best_test$probs>=0.5)
table(HR_best_test$predleft,HR_best_test$left)

#error_HR_best_train = (FP + FN) / (FP + FN + TP + TN) = 0.1397
#error_HR_best_test = (FP + FN) / (FP + FN + TP + TN) = 0.1342

#YES

#The 2-fold CV error of the more complex logistic regression classifier less than the single logistic regression classifier
#In two-fold crossvlidation, the dataset is randomly splited into two subsets. The size of both subsets are equal. 
#Firstly by comparing to the simple logistic regression, the two-fold cross-validation of complex logistic regression has smaller error rate which mean it is more accurate. 
#Secondly, a small value of K (K=2) always work towards validation set approach wheases a higher valure of K can improve the accuracy of the measurement.




13 llibrary("MASS")
qdafit<-qda(left~average_montly_hours*satisfaction_level*number_project,data=HR_best_train)
temp<-predict(qdafit,data.frame(average_montly_hours=HR_best_test$average_montly_hours,satisfaction_level=HR_best_test$satisfaction_level,number_project=HR_best_test$number_project),type="response")
HR_best_test$probs4<-temp$posterior[,2]
testROC4<-performance(prediction(HR_best_test$probs3,HR_best_test$left),"tpr","fpr")
plot(testROC4)
abline(a=0, b= 1,lty=2)
testAUC4<-as.double(performance(prediction(HR_best_test$probs4,HR_best_test$left),"auc")@y.values)
testAUC4

#Logistic regression is to predict qualitative response for an observtion and defines the probability of an observation belonging to a categoty or a goup, and works for continous data. 
#LDA is used when a linear boundary is required classifiers and QDA is used to find a non-linear boundary between classifiers. 
#QDA can accurately model a wider range of problems than the liner methods. QDA can perform better in the presence of a limited number of traiing observtions because it does make some assumptions about the form of the decision boundary.


14 #Cluster is a good technique to visualising high dimensional or multidimensional data. 
#It can organise things or observations that are close together and separate them into groups. 
#It can give a good view or help understand in a very high dimensional dataset.

