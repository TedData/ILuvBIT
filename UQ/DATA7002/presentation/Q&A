为什么加了header可以骗过反爬虫系统

除了Python还有哪些可以实现爬虫

目前市面上的爬虫软件主要是用什么实现的

阿里巴巴的反爬虫系统应该很先进，还有没有其他可以骗过反爬虫的技术


爬取一些公司或者企业的信息，对企业或个人的危险这么大，那么我们确实应该对网页添加防护，来保护网页不能轻易的被爬取。你刚刚说可以通过添加header的方式来实现对网页的保护，那么我想请问，它是如何实现的，或者说，为什么加了header可以骗过反爬虫系统。
The web scrapes some company information, the danger to the company or individual is so great, then we really should add protection to the web, so that the web cannot be easily scraped. You just said that the protection of the web can be achieved by adding headers, so I would like to ask how it is achieved, in other words why adding headers can fool the anti-scraping system.


现在对于爬取网页信息，最常用到的是python，因为它是一个公开的编辑软件，我们可以轻易的搜索到一些关于爬虫的package，并直接使用它。那么我想请问，除了Python还有软件可以实现爬虫功能。
Now for web scraping, python is the most commonly used, because it is a public editing software, we can easily search for some scraping packages. Then I would like to ask, in addition to Python, there is also software that can implement web scraping functions.

目前市面上有很多不同种类的爬虫数据包，请问它是如何实现对网页上信息的摘取。
There are many different types of scrape data packages on the internet. How does it work to extract information on the web?

阿里巴巴做为中国最大的科技公司之一，它的反爬虫系统应该很先进，但是，想请问，有没有可以骗过这个反爬虫系统的技术。
Alibaba is one of the most excellent technology companies in China, its anti-scraping system should be very advanced, but I would like to ask if there is any technology that can fool its anti-scraping system.



